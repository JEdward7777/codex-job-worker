diff --git a/datas/dataset.py b/datas/dataset.py
index 3f1a296..881bb2a 100644
--- a/datas/dataset.py
+++ b/datas/dataset.py
@@ -15,25 +15,32 @@ def intersperse(lst: list, item: int):
     result = [item] * (len(lst) * 2 + 1)
     result[1::2] = lst
     return result
-    
+
 class StableDataset(Dataset):
     def __init__(self, filelist_path, hop_length):
-        self.filelist_path = filelist_path     
-        self.hop_length = hop_length  
-        
+        self.filelist_path = filelist_path
+        self.hop_length = hop_length
+
         self._load_filelist(filelist_path)
 
     def _load_filelist(self, filelist_path):
+        # Get the directory containing the JSON file for resolving relative paths
+        json_dir = os.path.dirname(os.path.abspath(filelist_path))
+
         filelist, lengths = [], []
         with open(filelist_path, 'r', encoding='utf-8') as f:
             for line in f:
                 line = json.loads(line.strip())
-                filelist.append((line['mel_path'], line['phone']))
+                mel_path = line['mel_path']
+                # Resolve relative paths relative to the JSON file location
+                if not os.path.isabs(mel_path):
+                    mel_path = os.path.join(json_dir, mel_path)
+                filelist.append((mel_path, line['phone']))
                 lengths.append(line['mel_length'])
-            
+
         self.filelist = filelist
         self.lengths = lengths # length is used for DistributedBucketSampler
-    
+
     def __len__(self):
         return len(self.filelist)
 
@@ -42,16 +49,16 @@ class StableDataset(Dataset):
         mel = torch.load(mel_path, map_location='cpu', weights_only=True)
         phone = torch.tensor(intersperse(cleaned_text_to_sequence(phone), 0), dtype=torch.long)
         return mel, phone
-    
+
 def collate_fn(batch):
     texts = [item[1] for item in batch]
     mels = [item[0] for item in batch]
     mels_sliced = [random_slice_tensor(mel) for mel in mels]
-    
+
     text_lengths = torch.tensor([text.size(-1) for text in texts], dtype=torch.long)
     mel_lengths = torch.tensor([mel.size(-1) for mel in mels], dtype=torch.long)
     mels_sliced_lengths = torch.tensor([mel_sliced.size(-1) for mel_sliced in mels_sliced], dtype=torch.long)
-    
+
     # pad to the same length
     texts_padded = torch.nested.to_padded_tensor(torch.nested.nested_tensor(texts), padding=0)
     mels_padded = torch.nested.to_padded_tensor(torch.nested.nested_tensor(mels), padding=0)
@@ -63,7 +70,7 @@ def collate_fn(batch):
 def random_slice_tensor(x: torch.Tensor):
     length = x.size(-1)
     if length < 12:
-        return x 
+        return x
     segmnt_size = random.randint(length // 12, length // 3)
     start = random.randint(0, length - segmnt_size)
     return x[..., start : start + segmnt_size]
\ No newline at end of file
diff --git a/text/japanese.py b/text/japanese.py
index 948702b..4bf1903 100644
--- a/text/japanese.py
+++ b/text/japanese.py
@@ -1,6 +1,9 @@
 import re
 from unidecode import unidecode
-import pyopenjtalk
+try:
+    import pyopenjtalk
+except ImportError:
+    pyopenjtalk = None
 
 
 # Regular expression matching Japanese without punctuation marks:
